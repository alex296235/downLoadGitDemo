[INFO] [2017-05-02 21:46:44][org.apache.hadoop.conf.Configuration.deprecation]session.id is deprecated. Instead, use dfs.metrics.session-id
[INFO] [2017-05-02 21:46:44][org.apache.hadoop.metrics.jvm.JvmMetrics]Initializing JVM Metrics with processName=JobTracker, sessionId=
[INFO] [2017-05-02 21:47:13][org.apache.hadoop.conf.Configuration.deprecation]session.id is deprecated. Instead, use dfs.metrics.session-id
[INFO] [2017-05-02 21:47:13][org.apache.hadoop.metrics.jvm.JvmMetrics]Initializing JVM Metrics with processName=JobTracker, sessionId=
[WARN] [2017-05-02 21:47:14][org.apache.hadoop.mapreduce.JobResourceUploader]No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] [2017-05-02 21:47:14][org.apache.hadoop.mapreduce.lib.input.FileInputFormat]Total input paths to process : 1
[INFO] [2017-05-02 21:47:14][org.apache.hadoop.mapreduce.JobSubmitter]number of splits:1
[INFO] [2017-05-02 21:47:14][org.apache.hadoop.mapreduce.JobSubmitter]Submitting tokens for job: job_local2121176721_0001
[INFO] [2017-05-02 21:47:14][org.apache.hadoop.mapreduce.Job]The url to track the job: http://localhost:8080/
[INFO] [2017-05-02 21:47:14][org.apache.hadoop.mapred.LocalJobRunner]OutputCommitter set in config null
[INFO] [2017-05-02 21:47:14][org.apache.hadoop.mapreduce.Job]Running job: job_local2121176721_0001
[INFO] [2017-05-02 21:47:14][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter]File Output Committer Algorithm version is 1
[INFO] [2017-05-02 21:47:14][org.apache.hadoop.mapred.LocalJobRunner]OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] [2017-05-02 21:47:14][org.apache.hadoop.mapred.LocalJobRunner]Waiting for map tasks
[INFO] [2017-05-02 21:47:14][org.apache.hadoop.mapred.LocalJobRunner]Starting task: attempt_local2121176721_0001_m_000000_0
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter]File Output Committer Algorithm version is 1
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.yarn.util.ProcfsBasedProcessTree]ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.Task] Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@52ee37af
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.MapTask]Processing split: hdfs://192.168.160.130:9000/test/input/wordCount.txt:0+63
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.MapTask](EQUATOR) 0 kvi 26214396(104857584)
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.MapTask]mapreduce.task.io.sort.mb: 100
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.MapTask]soft limit at 83886080
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.MapTask]bufstart = 0; bufvoid = 104857600
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.MapTask]kvstart = 26214396; length = 6553600
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.MapTask]Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.LocalJobRunner]
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.MapTask]Starting flush of map output
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.MapTask]Spilling map output
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.MapTask]bufstart = 0; bufend = 90; bufvoid = 104857600
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.MapTask]kvstart = 26214396(104857584); kvend = 26214364(104857456); length = 33/6553600
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.MapTask]Finished spill 0
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.Task]Task:attempt_local2121176721_0001_m_000000_0 is done. And is in the process of committing
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.LocalJobRunner]map
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.Task]Task 'attempt_local2121176721_0001_m_000000_0' done.
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.LocalJobRunner]Finishing task: attempt_local2121176721_0001_m_000000_0
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.LocalJobRunner]map task executor complete.
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.LocalJobRunner]Waiting for reduce tasks
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.LocalJobRunner]Starting task: attempt_local2121176721_0001_r_000000_0
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter]File Output Committer Algorithm version is 1
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.yarn.util.ProcfsBasedProcessTree]ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.Task] Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5c90f10e
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.ReduceTask]Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1eac58f6
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl]MergerManager: memoryLimit=1265788544, maxSingleShuffleLimit=316447136, mergeThreshold=835420480, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapreduce.task.reduce.EventFetcher]attempt_local2121176721_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapreduce.task.reduce.LocalFetcher]localfetcher#1 about to shuffle output of map attempt_local2121176721_0001_m_000000_0 decomp: 62 len: 66 to MEMORY
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput]Read 62 bytes from map-output for attempt_local2121176721_0001_m_000000_0
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl]closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->62
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapreduce.task.reduce.EventFetcher]EventFetcher is interrupted.. Returning
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.LocalJobRunner]1 / 1 copied.
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl]finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapreduce.Job]Job job_local2121176721_0001 running in uber mode : false
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapreduce.Job] map 100% reduce 0%
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.Merger]Merging 1 sorted segments
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.Merger]Down to the last merge-pass, with 1 segments left of total size: 53 bytes
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl]Merged 1 segments, 62 bytes to disk to satisfy reduce memory limit
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl]Merging 1 files, 66 bytes from disk
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl]Merging 0 segments, 0 bytes from memory into reduce
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.Merger]Merging 1 sorted segments
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.Merger]Down to the last merge-pass, with 1 segments left of total size: 53 bytes
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.LocalJobRunner]1 / 1 copied.
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.conf.Configuration.deprecation]mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.Task]Task:attempt_local2121176721_0001_r_000000_0 is done. And is in the process of committing
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.LocalJobRunner]1 / 1 copied.
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.Task]Task attempt_local2121176721_0001_r_000000_0 is allowed to commit now
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter]Saved output of task 'attempt_local2121176721_0001_r_000000_0' to hdfs://192.168.160.130:9000/test/out/_temporary/0/task_local2121176721_0001_r_000000
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.LocalJobRunner]reduce > reduce
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.Task]Task 'attempt_local2121176721_0001_r_000000_0' done.
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.LocalJobRunner]Finishing task: attempt_local2121176721_0001_r_000000_0
[INFO] [2017-05-02 21:47:15][org.apache.hadoop.mapred.LocalJobRunner]reduce task executor complete.
[INFO] [2017-05-02 21:47:16][org.apache.hadoop.mapreduce.Job] map 100% reduce 100%
[INFO] [2017-05-02 21:47:16][org.apache.hadoop.mapreduce.Job]Job job_local2121176721_0001 completed successfully
[INFO] [2017-05-02 21:47:16][org.apache.hadoop.mapreduce.Job]Counters: 35
	File System Counters
		FILE: Number of bytes read=546
		FILE: Number of bytes written=587024
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=126
		HDFS: Number of bytes written=40
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=9
		Map output records=9
		Map output bytes=90
		Map output materialized bytes=66
		Input split bytes=117
		Combine input records=9
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=66
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=26
		Total committed heap usage (bytes)=517996544
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=63
	File Output Format Counters 
		Bytes Written=40
[INFO] [2017-05-19 16:54:56][org.apache.hadoop.conf.Configuration.deprecation]session.id is deprecated. Instead, use dfs.metrics.session-id
[INFO] [2017-05-19 16:54:56][org.apache.hadoop.metrics.jvm.JvmMetrics]Initializing JVM Metrics with processName=JobTracker, sessionId=
[WARN] [2017-05-19 16:54:56][org.apache.hadoop.mapreduce.JobResourceUploader]No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] [2017-05-19 16:54:57][org.apache.hadoop.mapreduce.lib.input.FileInputFormat]Total input paths to process : 1
[INFO] [2017-05-19 16:54:57][org.apache.hadoop.mapreduce.JobSubmitter]number of splits:1
[INFO] [2017-05-19 16:54:57][org.apache.hadoop.mapreduce.JobSubmitter]Submitting tokens for job: job_local2094976577_0001
[INFO] [2017-05-19 16:54:57][org.apache.hadoop.mapreduce.Job]The url to track the job: http://localhost:8080/
[INFO] [2017-05-19 16:54:57][org.apache.hadoop.mapreduce.Job]Running job: job_local2094976577_0001
[INFO] [2017-05-19 16:54:57][org.apache.hadoop.mapred.LocalJobRunner]OutputCommitter set in config null
[INFO] [2017-05-19 16:54:58][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter]File Output Committer Algorithm version is 1
[INFO] [2017-05-19 16:54:58][org.apache.hadoop.mapred.LocalJobRunner]OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] [2017-05-19 16:54:58][org.apache.hadoop.mapred.LocalJobRunner]Error cleaning up job:job_local2094976577_0001
[WARN] [2017-05-19 16:54:58][org.apache.hadoop.mapred.LocalJobRunner]job_local2094976577_0001
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create directory /test/out/_temporary/0. Name node is in safe mode.
The reported blocks 0 needs additional 37 blocks to reach the threshold 0.9990 of total blocks 37.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1327)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3895)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:622)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:558)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:3000)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2970)
	at org.apache.hadoop.hdfs.DistributedFileSystem$21.doCall(DistributedFileSystem.java:1047)
	at org.apache.hadoop.hdfs.DistributedFileSystem$21.doCall(DistributedFileSystem.java:1043)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1061)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1036)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1881)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:313)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:511)
[INFO] [2017-05-19 16:54:58][org.apache.hadoop.mapreduce.Job]Job job_local2094976577_0001 running in uber mode : false
[INFO] [2017-05-19 16:54:58][org.apache.hadoop.mapreduce.Job] map 0% reduce 0%
[INFO] [2017-05-19 16:54:58][org.apache.hadoop.mapreduce.Job]Job job_local2094976577_0001 failed with state FAILED due to: NA
[INFO] [2017-05-19 16:54:59][org.apache.hadoop.mapreduce.Job]Counters: 0
[INFO] [2017-05-19 16:56:15][org.apache.hadoop.conf.Configuration.deprecation]session.id is deprecated. Instead, use dfs.metrics.session-id
[INFO] [2017-05-19 16:56:15][org.apache.hadoop.metrics.jvm.JvmMetrics]Initializing JVM Metrics with processName=JobTracker, sessionId=
[WARN] [2017-05-19 16:56:15][org.apache.hadoop.mapreduce.JobResourceUploader]No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] [2017-05-19 16:56:15][org.apache.hadoop.mapreduce.lib.input.FileInputFormat]Total input paths to process : 1
[INFO] [2017-05-19 16:56:15][org.apache.hadoop.mapreduce.JobSubmitter]number of splits:1
[INFO] [2017-05-19 16:56:16][org.apache.hadoop.mapreduce.JobSubmitter]Submitting tokens for job: job_local1744507186_0001
[INFO] [2017-05-19 16:56:16][org.apache.hadoop.mapreduce.Job]The url to track the job: http://localhost:8080/
[INFO] [2017-05-19 16:56:16][org.apache.hadoop.mapreduce.Job]Running job: job_local1744507186_0001
[INFO] [2017-05-19 16:56:16][org.apache.hadoop.mapred.LocalJobRunner]OutputCommitter set in config null
[INFO] [2017-05-19 16:56:16][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter]File Output Committer Algorithm version is 1
[INFO] [2017-05-19 16:56:16][org.apache.hadoop.mapred.LocalJobRunner]OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] [2017-05-19 16:56:16][org.apache.hadoop.mapred.LocalJobRunner]Error cleaning up job:job_local1744507186_0001
[WARN] [2017-05-19 16:56:16][org.apache.hadoop.mapred.LocalJobRunner]job_local1744507186_0001
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create directory /test/out/_temporary/0. Name node is in safe mode.
The reported blocks 0 needs additional 37 blocks to reach the threshold 0.9990 of total blocks 37.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1327)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3895)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:622)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:558)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:3000)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2970)
	at org.apache.hadoop.hdfs.DistributedFileSystem$21.doCall(DistributedFileSystem.java:1047)
	at org.apache.hadoop.hdfs.DistributedFileSystem$21.doCall(DistributedFileSystem.java:1043)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1061)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1036)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1881)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:313)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:511)
[INFO] [2017-05-19 16:56:17][org.apache.hadoop.mapreduce.Job]Job job_local1744507186_0001 running in uber mode : false
[INFO] [2017-05-19 16:56:17][org.apache.hadoop.mapreduce.Job] map 0% reduce 0%
[INFO] [2017-05-19 16:56:17][org.apache.hadoop.mapreduce.Job]Job job_local1744507186_0001 failed with state FAILED due to: NA
[INFO] [2017-05-19 16:56:17][org.apache.hadoop.mapreduce.Job]Counters: 0
